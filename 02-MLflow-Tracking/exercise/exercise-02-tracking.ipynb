{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# TODO: import mlflow\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the tracking URI to your localhost ip http://127.0.0.1:PORT/ \n",
    "# (PORT is usually 5000)\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Start a new mlflow run \"mlflow-tracking\" and export its run_id\n",
    "# IMPORTANT: Keep the naming of \"exercise_2_id\", and \"tracking_run_id\" as they are needed later\n",
    "exercise_2_id = mlflow.set_experiment(\"exercise-02\").experiment_id\n",
    "tracking_run_id = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Params\n",
    "# TODO log a learning_rate of 0.01\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"epochs\": 0.05, \"final_activation\": \"sigmoid\"}\n",
    "# TODO: log the above mentioned parameters to mlflow\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Tags\n",
    "# TODO: set an \"environment\" tag to \"dev\" and a \"username\" tag to \"your name\"\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Metrics\n",
    "# TODO: Log a F-score of 0.7\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run() # end the previous run to be able to start a new one\n",
    "\n",
    "# TODO: log the following accuracies as metrics to your logistic-regression run from the previous experiment\n",
    "# \"exercise-01.1-YOUR-NAME\" with its run_id and experiment_id. HINT: Look also in the web UI\n",
    "lr_run_id = \"INSERT-RUN-ID\"\n",
    "experiment_id = \"INSERT-EXPERIMENT-ID\"\n",
    "accuracy_list = [0.6, 0.6, 0.8, 0.9]\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Artifacts\n",
    "mlflow.set_experiment(experiment_id=exercise_2_id)\n",
    "mlflow.start_run(run_id=tracking_run_id)\n",
    "\n",
    "\n",
    "# Create an example file output/test.txt\n",
    "file_path = \"outputs/test.txt\"\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(\"hello world!\")\n",
    "\n",
    "# TODO: store the previous created file in the data/subfolder subdirectory\n",
    "???\n",
    "\n",
    "# TODO: get and print the URI where the artifacts have been logged to\n",
    "???\n",
    "\n",
    "# End previous runs\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Autolog\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {\"n_estimators\": 4, \"random_state\": 42}\n",
    "\n",
    "# TODO: start autologging the upcoming run\n",
    "???\n",
    "\n",
    "run_name = 'autologging model example'\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    rfr = RandomForestRegressor(**params).fit(np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]]), [1, 1, 1])\n",
    "    print(f\"run_id: {run.info.run_id}\")\n",
    "\n",
    "# TODO: stop autologging\n",
    "???"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
