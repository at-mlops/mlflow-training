{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow \n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path \n",
    "import json \n",
    "# TODO: import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the tracking URI to your localhost ip http://127.0.0.1:PORT/ \n",
    "# (PORT is usually 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Start a new mlflow run \"mlflow-tracking\" and export its run_id\n",
    "# IMPORTANT: Keep the naming of \"exercise_2_id\", and \"tracking_run_id\" as they are needed later\n",
    "experiment_name = \"exercise-02\"\n",
    "run_name = \"mlflow-tracking\"\n",
    "\n",
    "experiment = #TODO\n",
    "exercise_2_id = #TODO \n",
    "run = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log single parameter\n",
    "# TODO log a learning_rate of 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log multiple parameters\n",
    "params = {\"epochs\": 20, \"num\": \"sigmoid\"}\n",
    "# TODO: log the above mentioned parameters to mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_training import __version__\n",
    "# TODO: set an \"environment\" tag to \"dev\" and a \"username\" tag to \"your name\" and version to __version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Metrics\n",
    "# TODO: Log a F-score of 0.7\n",
    "\n",
    "# TODO Log multiple metrics (accuracy, recall, precision)\n",
    "metrics = {\n",
    "    \"accuracy\": 0.98, \n",
    "    \"recall\": 0.97, \n",
    "    \"precision\": 0.99\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "# You can also log metrics during an experiment for example loss\n",
    "# imagine you have a training run and every batch produces a loss value \n",
    "loss_values = np.logspace(4, 0, num=100)\n",
    "\n",
    "for batch_num, loss in enumerate(loss_values):\n",
    "    #TODO log the metric for every batch\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the active mlflow run (`mlflow-tracking`) in the experiment `exercise-02` and select `loss` in the run overview to observe the model during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your artifact is stored here:  mlflow-artifacts:/264992445669677316/1ec005054aaf41d0a6cdd124526de25c/artifacts\n"
     ]
    }
   ],
   "source": [
    "# Create an example file output/test.txt\n",
    "with TemporaryDirectory() as temp_dir: \n",
    "    file_path = Path(temp_dir) / \"config.json\"\n",
    "\n",
    "    with file_path.open(\"w\") as outfile:\n",
    "        json.dump(params, outfile)\n",
    "    \n",
    "    #TODO log the artifact \n",
    "\n",
    "artifact_uri = mlflow.get_artifact_uri()\n",
    "print(f\"your artifact is stored here: \", artifact_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/27 16:38:43 INFO mlflow.tracking._tracking_service.client: üèÉ View run mlflow-tracking at: http://127.0.0.1:5000/#/experiments/264992445669677316/runs/1ec005054aaf41d0a6cdd124526de25c.\n",
      "2024/08/27 16:38:43 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/264992445669677316.\n"
     ]
    }
   ],
   "source": [
    "# End previous runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at your run `mlflow-tracking` on the UI and check out everything you logged: \n",
    "- Parameters \n",
    "- Tags\n",
    "- Metrics \n",
    "- Artifacts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autolog \n",
    "MLFlow also provides a Autolog function for some Frameworks. With SKlearn this works very well if you want just some basic metrics and logs for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/27 16:42:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\florian.krempl.AT\\Documents\\projects\\trainings\\mlflow-training\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\"\n",
      "2024/08/27 16:42:31 INFO mlflow.tracking._tracking_service.client: üèÉ View run autologging model example at: http://127.0.0.1:5000/#/experiments/264992445669677316/runs/fbdd4fe2b19b4d56954ac762b9b28950.\n",
      "2024/08/27 16:42:31 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/264992445669677316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: fbdd4fe2b19b4d56954ac762b9b28950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {\"n_estimators\": 4, \"random_state\": 42}\n",
    "\n",
    "# TODO: start autologging the upcoming run\n",
    "\n",
    "run_name = 'autologging model example'\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    rfr = RandomForestRegressor(**params).fit(np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]]), np.array([1, 1, 1]))\n",
    "    print(f\"run_id: {run.info.run_id}\")\n",
    "\n",
    "# TODO: stop autologging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO search for runs in our experiment and sort them by accuracy  \n",
    "runs_df = #TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
